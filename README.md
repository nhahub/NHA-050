# ðŸ›¡ï¸ Cartify Automation Framework | Team 50

**QA Lead:** Abdallah Mohamed  
**Current Status:** âš ï¸ Conditional Pass (Critical Defects Pending Fix)  
**Test Coverage:** Hybrid (Manual + Automated + API)

---

## ðŸ“– Project Abstract
This repository hosts the **Automated Testing Framework** for the Cartify E-Commerce platform. Unlike a standard "record-and-playback" script, this project utilizes a modular **Java Selenium** architecture designed for scalability, maintainability, and robust failure analysis.

The framework validates critical business flows including **User Registration, Product Search, Shopping Cart Logic, and Checkout Transaction integrity**.

## ðŸ› ï¸ Technical Architecture
We engineered a custom framework using the **Page Object Model (POM)** design pattern.

### Core Stack
* **Language:** Java 17
* **Web Driver:** Selenium 4.27
* **Test Runner:** TestNG 7.10
* **Reporting:** ExtentReports 5 (HTML)
* **Build Tool:** Maven

### Key Framework Features
1.  **Page Object Model (POM):**
    * **Logic Separation:** We separated locators (in `/pages`) from assertions (in `/tests`). This ensures that if a UI ID changes, we only update one file, not fifty.
    * *Evidence:* See `LoginPage.java` vs `EndToEndFlowTest.java`.
2.  **Self-Healing & Synchronization:**
    * **Explicit Waits:** `BasePage.java` implements dynamic waits to handle network lag, eliminating "flaky" tests caused by slow loading elements.
3.  **Automated Failure Capture:**
    * **Screenshot Listener:** A custom `TestListener` automatically captures a screenshot the exact moment a test fails and attaches it to the execution report.
4.  **Data-Driven Logic:**
    * The framework uses dynamic data generation (e.g., `UUID` for unique emails) to allow repeated execution without data collision.

## ðŸ“Š Test Execution Strategy
The suite is divided into functional areas defined in `testng.xml`:

1.  **Infrastructure Sanity:** Verifies the environment before heavy lifting.
2.  **E2E Flows:** Full user journey (Reg -> Login -> Wishlist).
3.  **Cart & Checkout:** Validates monetary calculations and order submission.

### How to Run
```bash
# Execute the full Regression Suite
mvn clean test

# Execute only the End-to-End flow
mvn -Dtest=EndToEndFlowTest test
ðŸ“‰ Quality Metrics (From Master Test Plan)
Total Test Cases: 60 (Manual + Auto)

Defects Found: 20 Valid Defects

Critical Severity: High (Checkout Empty Cart Bug)

Release Decision: NO GO (Pending Fixes)

Team 50 | QA Department


---

### Part 2: Defense SIQs (Standard Interview Questions)

These are the technical questions an evaluator will ask to see if you actually understand the code or just copied it.



#### Category 1: Architecture & Framework
**Q1: Why did you choose the Page Object Model (POM) instead of just writing everything in one test file?**
> **Winning Answer:** "Writing everything in one file creates 'Spaghetti Code'. If the developer changes the ID of the 'Login' button, I would have to find and fix it in 50 different test cases. With POM, I only fix it in the `LoginPage.java` file, and all my tests work again immediately. It reduces maintenance time by 80%."

**Q2: How do you handle synchronization? Did you use `Thread.sleep`?**
> **Winning Answer:** "We strictly avoided `Thread.sleep` because it slows down execution unnecessarily. Instead, we built a wrapper in our `BasePage` class that uses **Explicit Waits** (`WebDriverWait`). This waits *only* until the element is visible or clickable, then immediately proceeds, making our tests faster and more reliable."

**Q3: Explain your `BaseTest` class. Why is it there?**
> **Winning Answer:** "`BaseTest` is our setup engine. It uses `@BeforeMethod` to launch the browser and `@AfterMethod` to quit it. It ensures that every single test starts with a fresh, clean browser state so that data from a previous test doesn't corrupt the current one."

#### Category 2: Defect & Quality Strategy
**Q4: Your report says 'Conditional Pass'. Why didn't you pass the project?**
> **Winning Answer:** "As a QA Lead, my job is to protect the user experience. We found a **Critical (P1)** defect in the Checkout flow where a user can place an order with an empty cart. This affects the business revenue directly. Until this is fixed, I cannot sign off on a production release."

**Q5: How do you debug a test that failed in the middle of the night?**
> **Winning Answer:** "We integrated **ExtentReports** with a **TestListener**. If a test fails, the listener automatically triggers a screenshot capture of the browser at that exact moment. I don't need to re-run the test to see what happened; I just look at the HTML report."

#### Category 3: Advanced / Tricky Questions
**Q6: What happens if the 'Products' page is empty in the test environment? Does your test fail?**
> **Winning Answer:** "We anticipated that. In `EndToEndFlowTest`, we added logic that checks if the product list is empty. If it is, we inject a 'Mock Product' using JavaScript so that the test can continue to verify the 'Add to Wishlist' functionality. This makes our test robust even in unstable environments."

**Q7: How did you ensure you tested everything requested?**
> **Winning Answer:** "We created a **Traceability Matrix**. We mapped every Requirement ID (like FR-U-001) to a specific Test Case ID. This ensures 100% coverage of the requirements."
